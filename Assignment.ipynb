{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f079240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import string\n",
    "import textstat\n",
    "import nltk\n",
    "from io import BytesIO\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90b63cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for extraction of text from URL\n",
    "def extract_data_from_url(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            # content selection by class_name & attribute\n",
    "            content_elements =soup.find_all(class_='td-post-content tagdiv-type') + soup.find_all(attrs={\"data-td-block-uid\": \"tdi_130\"})\n",
    "            content = '\\n'.join(element.get_text() for element in content_elements)\n",
    "            return content\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching data from {url}: {e}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5611f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_words(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        words = [word.strip().lower() for word in file.readlines()]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25d5006c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_positive_score(text, positive_words_file):\n",
    "    positive_words = read_words(positive_words_file)\n",
    "    words = word_tokenize(text.lower())\n",
    "    positive_word_count = sum(1 for word in words if word in positive_words)\n",
    "    total_words = len(words)\n",
    "    positive_score = (positive_word_count / max(total_words, 1)) * 100\n",
    "    return positive_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1dcdc4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_negative_score(text,negative_words_file):\n",
    "    negative_words = read_words(negative_words_file) \n",
    "    words = word_tokenize(text.lower()) \n",
    "    negative_word_count = sum(1 for word in words if word in negative_words)\n",
    "    total_words = len(words)\n",
    "    negative_score = (negative_word_count / max(total_words, 1)) * 100\n",
    "    return negative_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70f7e56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sentiment_scores(pos_score,neg_score,total_words):\n",
    "    polarity_score = (pos_score - neg_score) / (pos_score + neg_score + 0.000001)\n",
    "    subjectivity_score = (pos_score + neg_score) / (total_words + 0.000001)\n",
    "    return polarity_score, subjectivity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07517161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_avg_word_length(text):\n",
    "    words = word_tokenize(text.lower())\n",
    "    total_characters = sum(len(word) for word in words)\n",
    "    total_words = len(words)\n",
    "    if total_words > 0:\n",
    "        avg_word_length = total_characters / total_words\n",
    "    else:\n",
    "        avg_word_length = 0\n",
    "    return avg_word_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6160b493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def calculate_personal_pronouns(text):\n",
    "    personal_pronouns = ['I', 'we', 'my', 'ours', 'us']\n",
    "    pronoun_counts = {pronoun.lower(): 0 for pronoun in personal_pronouns}\n",
    "    pattern = r'\\b(?:{})\\b(?!S)'.format('|'.join(personal_pronouns))\n",
    "    matches = re.findall(pattern, text, flags=re.IGNORECASE) # for ignorning 'US' text\n",
    "    for match in matches:\n",
    "        pronoun_counts[match.lower()] += 1\n",
    "    return pronoun_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "761e3186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate text statistics\n",
    "def calculate_text_statistics(text,positive_words,negative_words):\n",
    "    if text:\n",
    "        try:\n",
    "            sentences = sent_tokenize(text)\n",
    "            total_sentences = len(sentences)\n",
    "            words = word_tokenize(text)\n",
    "            total_words = len(words)\n",
    "            pos_score = calculate_positive_score(text,positive_words)\n",
    "            neg_score = calculate_negative_score(text,negative_words)\n",
    "            polarity_score, subjectivity_score = calculate_sentiment_scores(pos_score,neg_score,total_words)\n",
    "            return {\n",
    "                'POSITIVE SCORE': pos_score,\n",
    "                'NEGATIVE SCORE':neg_score,\n",
    "                'POLARITY SCORE': polarity_score,\n",
    "                'SUBJECTIVITY SCORE': subjectivity_score,\n",
    "                'AVG SENTENCE LENGTH': total_words / max(total_sentences, 1),\n",
    "                'PERCENTAGE OF COMPLEX WORDS': (textstat.lexicon_count(text, False) / max(total_words, 1)) * 100,\n",
    "                'FOG INDEX': textstat.gunning_fog(text),\n",
    "                'AVG NUMBER OF WORDS PER SENTENCE': total_words / max(total_sentences, 1),\n",
    "                'COMPLEX WORD COUNT': textstat.lexicon_count(text, False),\n",
    "                'WORD COUNT': total_words,\n",
    "                'SYLLABLE PER WORD': textstat.syllable_count(text) / max(total_words, 1),\n",
    "                'PERSONAL PRONOUNS': calculate_personal_pronouns(text),\n",
    "                'AVG WORD LENGTH': calculate_avg_word_length(text)\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating text statistics: {e}\")\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc338e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for clean file with the help of stop_words files\n",
    "def load_stop_words(file_paths):\n",
    "    stop_words = set()\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'r') as file:\n",
    "            words = file.read().splitlines()\n",
    "            stop_words.update(words)\n",
    "    return stop_words\n",
    "def clean_text(text, stop_words):\n",
    "    words = text.split()\n",
    "    words = [word.strip(string.punctuation) for word in words]\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    cleaned_text = ' '.join(filtered_words)\n",
    "    return cleaned_text\n",
    "stop_words_files = ['StopWords/StopWords_Auditor.txt', \n",
    "                    'StopWords/StopWords_Currencies.txt',\n",
    "                    'StopWords/StopWords_DatesandNumbers.txt', \n",
    "                    'StopWords/StopWords_Generic.txt', \n",
    "                    'StopWords/StopWords_GenericLong.txt', \n",
    "                    'StopWords/StopWords_Geographic.txt', \n",
    "                    'StopWords/StopWords_Names.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3746a610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to Output_Data_Structure.xlsx\n"
     ]
    }
   ],
   "source": [
    "#main code block\n",
    "#code for import file and export resultant file(Output_Data_Structure.xlsx)\n",
    "\n",
    "excel_url = 'Input.xlsx'\n",
    "positive_words='positive-words.txt'\n",
    "negative_words='negative-words.txt'\n",
    "excel_data = pd.read_excel(excel_url)\n",
    "new_data = pd.DataFrame(columns=[\n",
    "    'URL_ID', 'URL', 'POSITIVE SCORE', 'NEGATIVE SCORE', 'POLARITY SCORE',\n",
    "    'SUBJECTIVITY SCORE', 'AVG SENTENCE LENGTH', 'PERCENTAGE OF COMPLEX WORDS',\n",
    "    'FOG INDEX', 'AVG NUMBER OF WORDS PER SENTENCE', 'COMPLEX WORD COUNT',\n",
    "    'WORD COUNT', 'SYLLABLE PER WORD', 'PERSONAL PRONOUNS', 'AVG WORD LENGTH'\n",
    "])\n",
    "i=0\n",
    "for index, row in excel_data.iterrows():\n",
    "    url = row['URL']\n",
    "    url_id = row['URL_ID']\n",
    "    data = extract_data_from_url(url)\n",
    "    if data:\n",
    "        stop_words = load_stop_words(stop_words_files)\n",
    "        cleaned_text = clean_text(data, stop_words)\n",
    "        statistics = calculate_text_statistics(cleaned_text,positive_words,negative_words)\n",
    "        extracted_data = {\n",
    "            'URL_ID': url_id,\n",
    "            'URL': url,\n",
    "            **statistics,\n",
    "        }\n",
    "        new_data = pd.concat([new_data, pd.DataFrame([extracted_data])], ignore_index=True)\n",
    "new_excel_file = 'Output_Data_Structure.xlsx'\n",
    "new_data.to_excel(new_excel_file, index=False)\n",
    "print(f\"Data saved to {new_excel_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4a1179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4073a9e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da167e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
